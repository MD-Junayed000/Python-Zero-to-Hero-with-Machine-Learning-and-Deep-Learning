{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "21b0a96f-7099-4f2b-a489-7863adadaeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,SimpleRNN,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ed6e32ab-b7a7-4d10-816c-7109d845c83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French macaroon is so tasty</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work is horrible</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am upset</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>throw the ball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good joke</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>lets brunch some day</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>dance with me</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>she is a bully</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>she plays baseball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>I like it when people smile</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0   1\n",
       "0    French macaroon is so tasty   4\n",
       "1               work is horrible   3\n",
       "2                     I am upset  3 \n",
       "3                 throw the ball  1 \n",
       "4                      Good joke   2\n",
       "..                           ...  ..\n",
       "178         lets brunch some day   4\n",
       "179                dance with me   2\n",
       "180               she is a bully   3\n",
       "181           she plays baseball   1\n",
       "182  I like it when people smile   2\n",
       "\n",
       "[183 rows x 2 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('emoji_data.csv',header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "584055cc-ccb8-432c-a02c-77493a39702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now we are importing Emoji Library to map this Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "496b4a48-7a3c-4650-965e-6b5a5c52f1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d7522814-15b6-4ee8-93ab-973ff0d51183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8bc85c55-29af-485c-a49a-a2370106a75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'❤️'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(':red_heart:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c739b4b1-e67f-4bfa-b0c3-fdad12129861",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = {\n",
    "    0: \":red_heart:\",\n",
    "    1: \":baseball:\",\n",
    "    2: \":grinning_face_with_big_eyes:\",\n",
    "    3: \":disappointed_face:\",\n",
    "    4: \":fork_and_knife_with_plate:\"\n",
    "}\n",
    "\n",
    "def label_to_emoji(label): ############################\n",
    "    return emoji.emojize(emoji_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9b561091-f095-483b-bfa4-453cd442d080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['French macaroon is so tasty', 'work is horrible', 'I am upset',\n",
       "       'throw the ball', 'Good joke',\n",
       "       'what is your favorite baseball game', 'I cooked meat',\n",
       "       'stop messing around', 'I want chinese food',\n",
       "       'Let us go play baseball', 'you are failing this exercise',\n",
       "       'yesterday we lost again', 'Good job', 'ha ha ha it was so funny',\n",
       "       'I will have a cheese cake', 'Why are you feeling bad',\n",
       "       'I want to joke', 'I never said yes for this',\n",
       "       'the party is cancelled', 'where is the ball', 'I am frustrated',\n",
       "       'ha ha ha lol', 'she said yes', 'he got a raise',\n",
       "       'family is all I have', 'he can pitch really well',\n",
       "       'I love to the stars and back', 'do you like pizza ',\n",
       "       'You totally deserve this prize', 'I miss you so much',\n",
       "       'I like your jacket ', 'she got me a present',\n",
       "       'will you be my valentine', 'you failed the midterm',\n",
       "       'Who is down for a restaurant', 'valentine day is near',\n",
       "       'Great so awesome', 'do you have a ball', 'he can not do anything',\n",
       "       'he likes baseball', 'We had such a lovely dinner tonight',\n",
       "       'vegetables are healthy', 'he is a good friend',\n",
       "       'never talk to me again', 'i miss her', 'food is life',\n",
       "       'I am having fun', 'So bad that you cannot come with us',\n",
       "       'do you want to join me for dinner ', 'I like to smile',\n",
       "       'he did an amazing job', 'Stop shouting at me',\n",
       "       'I love taking breaks',\n",
       "       'You are incredibly intelligent and talented',\n",
       "       'I am proud of your achievements', 'So sad you are not coming',\n",
       "       'funny', 'Stop saying bullshit',\n",
       "       'Bravo for the announcement it got a lot of traction',\n",
       "       'This specialization is great',\n",
       "       'I was waiting for her for two hours ',\n",
       "       'she takes forever to get ready ',\n",
       "       'My grandmother is the love of my life', 'I will celebrate soon',\n",
       "       'my code is working but the grader gave me zero',\n",
       "       'She is the cutest person I have ever seen', 'he is laughing',\n",
       "       'I adore my dogs', 'I love you mum', 'great job',\n",
       "       'How dare you ask that', 'this guy was such a joke',\n",
       "       'I love indian food', 'Are you down for baseball this afternoon',\n",
       "       'this is bad', 'Your stupidity has no limit', 'I love my dad',\n",
       "       'Do you want to give me a hug', 'this girl was mean',\n",
       "       'I am excited', 'i miss him', 'What is wrong with you',\n",
       "       'they are so kind and friendly',\n",
       "       'I am so impressed by your dedication to this project',\n",
       "       'we made it', 'I am ordering food', 'Sounds like a fun plan ha ha',\n",
       "       'I am so happy for you', 'Miss you so much', 'I love you',\n",
       "       'this joke is killing me haha',\n",
       "       'You are not qualified for this position', 'miss you my dear',\n",
       "       'I want to eat', 'I am so excited to see you after so long',\n",
       "       'he is the best player', 'What a fun moment',\n",
       "       'my algorithm performs poorly', 'Stop shouting at me',\n",
       "       'her smile is so charming', 'It is the worst day in my life',\n",
       "       'he is handsome', 'no one likes him', 'she is attractive',\n",
       "       'It was funny lol', 'he is so cute', 'you did well on you exam',\n",
       "       'I think I will end up alone', 'Lets have food together',\n",
       "       'too bad that you were not here', 'I want to go play',\n",
       "       'you are a loser', 'I am starving', 'you suck', 'Congratulations',\n",
       "       'you could not solve it', 'I lost my wallet',\n",
       "       'she did not answer my text ', 'That catcher sucks ',\n",
       "       'See you at the restaurant', 'I boiled rice', 'I said yes',\n",
       "       'candy is life ', 'the game just finished',\n",
       "       'The first base man got the ball',\n",
       "       'congratulations on your acceptance',\n",
       "       'The assignment is too long ', 'lol',\n",
       "       'I got humiliated by my sister', 'I want to eat',\n",
       "       'the lectures are great though ', 'you did not do your homework',\n",
       "       'The baby is adorable', 'Bravo', 'I missed you',\n",
       "       'I am looking for a date', 'where is the food', 'you are awful',\n",
       "       'any suggestions for dinner', 'she is happy',\n",
       "       'I am always working', 'This is so funny', 'you got a down grade',\n",
       "       'I want to have sushi for dinner', 'she smiles a lot',\n",
       "       'The chicago cubs won again', 'I got approved', 'cookies are good',\n",
       "       'I hate him', 'I am going to the stadium',\n",
       "       'I am very disappointed', 'I am proud of you forever',\n",
       "       'This girl is messing with me', 'Congrats on the new job',\n",
       "       'enjoy your break', 'go away', 'I worked during my birthday',\n",
       "       'Congratulation fon have a baby', 'I am hungry',\n",
       "       'She is my dearest love', 'she is so cute', 'I love dogs',\n",
       "       'I did not have breakfast ', 'my dog just had a few puppies',\n",
       "       'I like you a lot', 'he had to make a home run',\n",
       "       'I am at the baseball game', 'are you serious ha ha',\n",
       "       'I like to laugh', 'Stop making this joke ha ha ha',\n",
       "       'you two are cute', 'This stupid grader is not working',\n",
       "       'What you did was awesome', 'My life is so boring',\n",
       "       'he did not answer', 'lets exercise', 'you brighten my day',\n",
       "       'I will go dance', 'lets brunch some day', 'dance with me',\n",
       "       'she is a bully', 'she plays baseball',\n",
       "       'I like it when people smile'], dtype=object)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data[0].values ## values dile numpy array mtn hoi\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "99ca9a3a-3e88-4f28-ba81-40b427fb9fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4', '3', '3 ', '1 ', '2', '1', '4', '3', '4', '1', '3', '3 ', '2',\n",
       "       '2', '4', '3', '2', '3 ', '3 ', '1', '3 ', '2', '2', '2', '0', '1',\n",
       "       '0', '4 ', '2', '0v2', '2', '0', '0', '3 ', '4', '0', '2', '1',\n",
       "       '3', '1', '0', '4', '0 ', '3', '0 ', '4', '2', '3 ', '4', '2 ',\n",
       "       '2', '3', '0', '2', '2', '3 ', '2', '3', '2', '2', '3 ', '3', '0 ',\n",
       "       '2', '3', '0', '2', '0', '0 ', '2', '3', '2', '4', '1', '3', '3',\n",
       "       '0', '0', '3', '2', '0', '3', '0', '2', '2', '4', '2', '2', '0',\n",
       "       '0', '2', '3', '0', '4', '2', '1', '2', '3', '3', '2', '3', '0',\n",
       "       '3', '0', '2', '0', '2', '3', '4', '3', '1', '3', '4', '3', '2',\n",
       "       '3', '3', '3', '1', '4', '4', '2', '2', '1', '1', '2', '3', '2',\n",
       "       '3', '4', '2', '3', '0', '2', '0', '0', '4', '3', '4', '2', '3',\n",
       "       '2', '3', '4', '2', '1', '2', '4', '3', '1', '3', '2', '3', '2',\n",
       "       '2', '3', '3', '2', '4', '0', '0', '0', '3', '0', '0', '1', '1',\n",
       "       '2', '2', '2', '0', '3', '2', '3', '3', '1', '2', '2', '4', '2',\n",
       "       '3', '1', '2'], dtype=object)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data[1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8269af5a-c853-4583-842b-9d245ade16bf",
   "metadata": {},
   "source": [
    "# Embedding(Word Embedding using pre-trained model glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a28236be-659f-473c-8bee-4ec0e855184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('glove.6B.100d.txt','r',encoding='utf8') ## for every word/symbol there is embedding of 100 vector size \n",
    "content=file.readlines()\n",
    "file.close()\n",
    "#content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f4178df1-b3f7-482d-91d2-e2e8937f2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding={}\n",
    "\n",
    "for line in content[:2]:\n",
    "    line=line.split()\n",
    "    #print(line)\n",
    "    embedding[line[0]]=np.array(line[1:],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "55bbba8e-311a-411d-8a1a-d965ca9be5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "        -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "         0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "        -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "         0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "        -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "         0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "         0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "        -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "        -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "        -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "        -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "        -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "        -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "        -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "         0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "        -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ]),\n",
       " ',': array([-0.10767  ,  0.11053  ,  0.59812  , -0.54361  ,  0.67396  ,\n",
       "         0.10663  ,  0.038867 ,  0.35481  ,  0.06351  , -0.094189 ,\n",
       "         0.15786  , -0.81665  ,  0.14172  ,  0.21939  ,  0.58505  ,\n",
       "        -0.52158  ,  0.22783  , -0.16642  , -0.68228  ,  0.3587   ,\n",
       "         0.42568  ,  0.19021  ,  0.91963  ,  0.57555  ,  0.46185  ,\n",
       "         0.42363  , -0.095399 , -0.42749  , -0.16567  , -0.056842 ,\n",
       "        -0.29595  ,  0.26037  , -0.26606  , -0.070404 , -0.27662  ,\n",
       "         0.15821  ,  0.69825  ,  0.43081  ,  0.27952  , -0.45437  ,\n",
       "        -0.33801  , -0.58184  ,  0.22364  , -0.5778   , -0.26862  ,\n",
       "        -0.20425  ,  0.56394  , -0.58524  , -0.14365  , -0.64218  ,\n",
       "         0.0054697, -0.35248  ,  0.16162  ,  1.1796   , -0.47674  ,\n",
       "        -2.7553   , -0.1321   , -0.047729 ,  1.0655   ,  1.1034   ,\n",
       "        -0.2208   ,  0.18669  ,  0.13177  ,  0.15117  ,  0.7131   ,\n",
       "        -0.35215  ,  0.91348  ,  0.61783  ,  0.70992  ,  0.23955  ,\n",
       "        -0.14571  , -0.37859  , -0.045959 , -0.47368  ,  0.2385   ,\n",
       "         0.20536  , -0.18996  ,  0.32507  , -1.1112   , -0.36341  ,\n",
       "         0.98679  , -0.084776 , -0.54008  ,  0.11726  , -1.0194   ,\n",
       "        -0.24424  ,  0.12771  ,  0.013884 ,  0.080374 , -0.35414  ,\n",
       "         0.34951  , -0.7226   ,  0.37549  ,  0.4441   , -0.99059  ,\n",
       "         0.61214  , -0.35111  , -0.83155  ,  0.45293  ,  0.082577 ])}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "865da59e-810f-4817-9ad6-b20ede2a94fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding={}\n",
    "\n",
    "for line in content:\n",
    "    line=line.split()\n",
    "    #print(line)\n",
    "    embedding[line[0]]=np.array(line[1:],dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6429298d-fae1-4ccf-8943-7b2d71fa90b0",
   "metadata": {},
   "source": [
    "## now we have to convert our text into input token\n",
    "and the integer into one_Hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d0c58f5a-babb-4a2a-a480-890c7a001334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "808cdd9d-2471-4b9d-bb71-ff697dda0b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'you': 2,\n",
       " 'is': 3,\n",
       " 'the': 4,\n",
       " 'a': 5,\n",
       " 'so': 6,\n",
       " 'am': 7,\n",
       " 'my': 8,\n",
       " 'to': 9,\n",
       " 'this': 10,\n",
       " 'are': 11,\n",
       " 'ha': 12,\n",
       " 'for': 13,\n",
       " 'she': 14,\n",
       " 'he': 15,\n",
       " 'me': 16,\n",
       " 'not': 17,\n",
       " 'love': 18,\n",
       " 'your': 19,\n",
       " 'want': 20,\n",
       " 'have': 21,\n",
       " 'it': 22,\n",
       " 'got': 23,\n",
       " 'like': 24,\n",
       " 'did': 25,\n",
       " 'baseball': 26,\n",
       " 'food': 27,\n",
       " 'was': 28,\n",
       " 'do': 29,\n",
       " 'joke': 30,\n",
       " 'stop': 31,\n",
       " 'will': 32,\n",
       " 'miss': 33,\n",
       " 'life': 34,\n",
       " 'ball': 35,\n",
       " 'good': 36,\n",
       " 'what': 37,\n",
       " 'go': 38,\n",
       " 'job': 39,\n",
       " 'funny': 40,\n",
       " 'bad': 41,\n",
       " 'day': 42,\n",
       " 'great': 43,\n",
       " 'dinner': 44,\n",
       " 'that': 45,\n",
       " 'with': 46,\n",
       " 'at': 47,\n",
       " 'of': 48,\n",
       " 'game': 49,\n",
       " 'we': 50,\n",
       " 'again': 51,\n",
       " 'said': 52,\n",
       " 'yes': 53,\n",
       " 'lol': 54,\n",
       " 'and': 55,\n",
       " 'down': 56,\n",
       " 'had': 57,\n",
       " 'her': 58,\n",
       " 'fun': 59,\n",
       " 'smile': 60,\n",
       " 'lot': 61,\n",
       " 'working': 62,\n",
       " 'him': 63,\n",
       " 'cute': 64,\n",
       " 'on': 65,\n",
       " 'lets': 66,\n",
       " 'messing': 67,\n",
       " 'us': 68,\n",
       " 'play': 69,\n",
       " 'exercise': 70,\n",
       " 'lost': 71,\n",
       " 'never': 72,\n",
       " 'where': 73,\n",
       " 'can': 74,\n",
       " 'well': 75,\n",
       " 'much': 76,\n",
       " 'valentine': 77,\n",
       " 'restaurant': 78,\n",
       " 'awesome': 79,\n",
       " 'likes': 80,\n",
       " 'such': 81,\n",
       " 'shouting': 82,\n",
       " 'proud': 83,\n",
       " 'bravo': 84,\n",
       " 'two': 85,\n",
       " 'forever': 86,\n",
       " 'grader': 87,\n",
       " 'dogs': 88,\n",
       " 'no': 89,\n",
       " 'girl': 90,\n",
       " 'excited': 91,\n",
       " 'by': 92,\n",
       " 'happy': 93,\n",
       " 'eat': 94,\n",
       " 'see': 95,\n",
       " 'long': 96,\n",
       " 'too': 97,\n",
       " 'congratulations': 98,\n",
       " 'answer': 99,\n",
       " 'just': 100,\n",
       " 'baby': 101,\n",
       " 'dance': 102,\n",
       " 'french': 103,\n",
       " 'macaroon': 104,\n",
       " 'tasty': 105,\n",
       " 'work': 106,\n",
       " 'horrible': 107,\n",
       " 'upset': 108,\n",
       " 'throw': 109,\n",
       " 'favorite': 110,\n",
       " 'cooked': 111,\n",
       " 'meat': 112,\n",
       " 'around': 113,\n",
       " 'chinese': 114,\n",
       " 'let': 115,\n",
       " 'failing': 116,\n",
       " 'yesterday': 117,\n",
       " 'cheese': 118,\n",
       " 'cake': 119,\n",
       " 'why': 120,\n",
       " 'feeling': 121,\n",
       " 'party': 122,\n",
       " 'cancelled': 123,\n",
       " 'frustrated': 124,\n",
       " 'raise': 125,\n",
       " 'family': 126,\n",
       " 'all': 127,\n",
       " 'pitch': 128,\n",
       " 'really': 129,\n",
       " 'stars': 130,\n",
       " 'back': 131,\n",
       " 'pizza': 132,\n",
       " 'totally': 133,\n",
       " 'deserve': 134,\n",
       " 'prize': 135,\n",
       " 'jacket': 136,\n",
       " 'present': 137,\n",
       " 'be': 138,\n",
       " 'failed': 139,\n",
       " 'midterm': 140,\n",
       " 'who': 141,\n",
       " 'near': 142,\n",
       " 'anything': 143,\n",
       " 'lovely': 144,\n",
       " 'tonight': 145,\n",
       " 'vegetables': 146,\n",
       " 'healthy': 147,\n",
       " 'friend': 148,\n",
       " 'talk': 149,\n",
       " 'having': 150,\n",
       " 'cannot': 151,\n",
       " 'come': 152,\n",
       " 'join': 153,\n",
       " 'an': 154,\n",
       " 'amazing': 155,\n",
       " 'taking': 156,\n",
       " 'breaks': 157,\n",
       " 'incredibly': 158,\n",
       " 'intelligent': 159,\n",
       " 'talented': 160,\n",
       " 'achievements': 161,\n",
       " 'sad': 162,\n",
       " 'coming': 163,\n",
       " 'saying': 164,\n",
       " 'bullshit': 165,\n",
       " 'announcement': 166,\n",
       " 'traction': 167,\n",
       " 'specialization': 168,\n",
       " 'waiting': 169,\n",
       " 'hours': 170,\n",
       " 'takes': 171,\n",
       " 'get': 172,\n",
       " 'ready': 173,\n",
       " 'grandmother': 174,\n",
       " 'celebrate': 175,\n",
       " 'soon': 176,\n",
       " 'code': 177,\n",
       " 'but': 178,\n",
       " 'gave': 179,\n",
       " 'zero': 180,\n",
       " 'cutest': 181,\n",
       " 'person': 182,\n",
       " 'ever': 183,\n",
       " 'seen': 184,\n",
       " 'laughing': 185,\n",
       " 'adore': 186,\n",
       " 'mum': 187,\n",
       " 'how': 188,\n",
       " 'dare': 189,\n",
       " 'ask': 190,\n",
       " 'guy': 191,\n",
       " 'indian': 192,\n",
       " 'afternoon': 193,\n",
       " 'stupidity': 194,\n",
       " 'has': 195,\n",
       " 'limit': 196,\n",
       " 'dad': 197,\n",
       " 'give': 198,\n",
       " 'hug': 199,\n",
       " 'mean': 200,\n",
       " 'wrong': 201,\n",
       " 'they': 202,\n",
       " 'kind': 203,\n",
       " 'friendly': 204,\n",
       " 'impressed': 205,\n",
       " 'dedication': 206,\n",
       " 'project': 207,\n",
       " 'made': 208,\n",
       " 'ordering': 209,\n",
       " 'sounds': 210,\n",
       " 'plan': 211,\n",
       " 'killing': 212,\n",
       " 'haha': 213,\n",
       " 'qualified': 214,\n",
       " 'position': 215,\n",
       " 'dear': 216,\n",
       " 'after': 217,\n",
       " 'best': 218,\n",
       " 'player': 219,\n",
       " 'moment': 220,\n",
       " 'algorithm': 221,\n",
       " 'performs': 222,\n",
       " 'poorly': 223,\n",
       " 'charming': 224,\n",
       " 'worst': 225,\n",
       " 'in': 226,\n",
       " 'handsome': 227,\n",
       " 'one': 228,\n",
       " 'attractive': 229,\n",
       " 'exam': 230,\n",
       " 'think': 231,\n",
       " 'end': 232,\n",
       " 'up': 233,\n",
       " 'alone': 234,\n",
       " 'together': 235,\n",
       " 'were': 236,\n",
       " 'here': 237,\n",
       " 'loser': 238,\n",
       " 'starving': 239,\n",
       " 'suck': 240,\n",
       " 'could': 241,\n",
       " 'solve': 242,\n",
       " 'wallet': 243,\n",
       " 'text': 244,\n",
       " 'catcher': 245,\n",
       " 'sucks': 246,\n",
       " 'boiled': 247,\n",
       " 'rice': 248,\n",
       " 'candy': 249,\n",
       " 'finished': 250,\n",
       " 'first': 251,\n",
       " 'base': 252,\n",
       " 'man': 253,\n",
       " 'acceptance': 254,\n",
       " 'assignment': 255,\n",
       " 'humiliated': 256,\n",
       " 'sister': 257,\n",
       " 'lectures': 258,\n",
       " 'though': 259,\n",
       " 'homework': 260,\n",
       " 'adorable': 261,\n",
       " 'missed': 262,\n",
       " 'looking': 263,\n",
       " 'date': 264,\n",
       " 'awful': 265,\n",
       " 'any': 266,\n",
       " 'suggestions': 267,\n",
       " 'always': 268,\n",
       " 'grade': 269,\n",
       " 'sushi': 270,\n",
       " 'smiles': 271,\n",
       " 'chicago': 272,\n",
       " 'cubs': 273,\n",
       " 'won': 274,\n",
       " 'approved': 275,\n",
       " 'cookies': 276,\n",
       " 'hate': 277,\n",
       " 'going': 278,\n",
       " 'stadium': 279,\n",
       " 'very': 280,\n",
       " 'disappointed': 281,\n",
       " 'congrats': 282,\n",
       " 'new': 283,\n",
       " 'enjoy': 284,\n",
       " 'break': 285,\n",
       " 'away': 286,\n",
       " 'worked': 287,\n",
       " 'during': 288,\n",
       " 'birthday': 289,\n",
       " 'congratulation': 290,\n",
       " 'fon': 291,\n",
       " 'hungry': 292,\n",
       " 'dearest': 293,\n",
       " 'breakfast': 294,\n",
       " 'dog': 295,\n",
       " 'few': 296,\n",
       " 'puppies': 297,\n",
       " 'make': 298,\n",
       " 'home': 299,\n",
       " 'run': 300,\n",
       " 'serious': 301,\n",
       " 'laugh': 302,\n",
       " 'making': 303,\n",
       " 'stupid': 304,\n",
       " 'boring': 305,\n",
       " 'brighten': 306,\n",
       " 'brunch': 307,\n",
       " 'some': 308,\n",
       " 'bully': 309,\n",
       " 'plays': 310,\n",
       " 'when': 311,\n",
       " 'people': 312}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(x)\n",
    "tokenizer.word_index # all words converted to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9c4ddb67-4928-4fb8-bdbd-756ab7285608",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6450fa9a-1e46-4752-8dd3-a2d3e262897a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[103, 104, 3, 6, 105],\n",
       " [106, 3, 107],\n",
       " [1, 7, 108],\n",
       " [109, 4, 35],\n",
       " [36, 30],\n",
       " [37, 3, 19, 110, 26, 49],\n",
       " [1, 111, 112],\n",
       " [31, 67, 113],\n",
       " [1, 20, 114, 27],\n",
       " [115, 68, 38, 69, 26],\n",
       " [2, 11, 116, 10, 70],\n",
       " [117, 50, 71, 51],\n",
       " [36, 39],\n",
       " [12, 12, 12, 22, 28, 6, 40],\n",
       " [1, 32, 21, 5, 118, 119],\n",
       " [120, 11, 2, 121, 41],\n",
       " [1, 20, 9, 30],\n",
       " [1, 72, 52, 53, 13, 10],\n",
       " [4, 122, 3, 123],\n",
       " [73, 3, 4, 35],\n",
       " [1, 7, 124],\n",
       " [12, 12, 12, 54],\n",
       " [14, 52, 53],\n",
       " [15, 23, 5, 125],\n",
       " [126, 3, 127, 1, 21],\n",
       " [15, 74, 128, 129, 75],\n",
       " [1, 18, 9, 4, 130, 55, 131],\n",
       " [29, 2, 24, 132],\n",
       " [2, 133, 134, 10, 135],\n",
       " [1, 33, 2, 6, 76],\n",
       " [1, 24, 19, 136],\n",
       " [14, 23, 16, 5, 137],\n",
       " [32, 2, 138, 8, 77],\n",
       " [2, 139, 4, 140],\n",
       " [141, 3, 56, 13, 5, 78],\n",
       " [77, 42, 3, 142],\n",
       " [43, 6, 79],\n",
       " [29, 2, 21, 5, 35],\n",
       " [15, 74, 17, 29, 143],\n",
       " [15, 80, 26],\n",
       " [50, 57, 81, 5, 144, 44, 145],\n",
       " [146, 11, 147],\n",
       " [15, 3, 5, 36, 148],\n",
       " [72, 149, 9, 16, 51],\n",
       " [1, 33, 58],\n",
       " [27, 3, 34],\n",
       " [1, 7, 150, 59],\n",
       " [6, 41, 45, 2, 151, 152, 46, 68],\n",
       " [29, 2, 20, 9, 153, 16, 13, 44],\n",
       " [1, 24, 9, 60],\n",
       " [15, 25, 154, 155, 39],\n",
       " [31, 82, 47, 16],\n",
       " [1, 18, 156, 157],\n",
       " [2, 11, 158, 159, 55, 160],\n",
       " [1, 7, 83, 48, 19, 161],\n",
       " [6, 162, 2, 11, 17, 163],\n",
       " [40],\n",
       " [31, 164, 165],\n",
       " [84, 13, 4, 166, 22, 23, 5, 61, 48, 167],\n",
       " [10, 168, 3, 43],\n",
       " [1, 28, 169, 13, 58, 13, 85, 170],\n",
       " [14, 171, 86, 9, 172, 173],\n",
       " [8, 174, 3, 4, 18, 48, 8, 34],\n",
       " [1, 32, 175, 176],\n",
       " [8, 177, 3, 62, 178, 4, 87, 179, 16, 180],\n",
       " [14, 3, 4, 181, 182, 1, 21, 183, 184],\n",
       " [15, 3, 185],\n",
       " [1, 186, 8, 88],\n",
       " [1, 18, 2, 187],\n",
       " [43, 39],\n",
       " [188, 189, 2, 190, 45],\n",
       " [10, 191, 28, 81, 5, 30],\n",
       " [1, 18, 192, 27],\n",
       " [11, 2, 56, 13, 26, 10, 193],\n",
       " [10, 3, 41],\n",
       " [19, 194, 195, 89, 196],\n",
       " [1, 18, 8, 197],\n",
       " [29, 2, 20, 9, 198, 16, 5, 199],\n",
       " [10, 90, 28, 200],\n",
       " [1, 7, 91],\n",
       " [1, 33, 63],\n",
       " [37, 3, 201, 46, 2],\n",
       " [202, 11, 6, 203, 55, 204],\n",
       " [1, 7, 6, 205, 92, 19, 206, 9, 10, 207],\n",
       " [50, 208, 22],\n",
       " [1, 7, 209, 27],\n",
       " [210, 24, 5, 59, 211, 12, 12],\n",
       " [1, 7, 6, 93, 13, 2],\n",
       " [33, 2, 6, 76],\n",
       " [1, 18, 2],\n",
       " [10, 30, 3, 212, 16, 213],\n",
       " [2, 11, 17, 214, 13, 10, 215],\n",
       " [33, 2, 8, 216],\n",
       " [1, 20, 9, 94],\n",
       " [1, 7, 6, 91, 9, 95, 2, 217, 6, 96],\n",
       " [15, 3, 4, 218, 219],\n",
       " [37, 5, 59, 220],\n",
       " [8, 221, 222, 223],\n",
       " [31, 82, 47, 16],\n",
       " [58, 60, 3, 6, 224],\n",
       " [22, 3, 4, 225, 42, 226, 8, 34],\n",
       " [15, 3, 227],\n",
       " [89, 228, 80, 63],\n",
       " [14, 3, 229],\n",
       " [22, 28, 40, 54],\n",
       " [15, 3, 6, 64],\n",
       " [2, 25, 75, 65, 2, 230],\n",
       " [1, 231, 1, 32, 232, 233, 234],\n",
       " [66, 21, 27, 235],\n",
       " [97, 41, 45, 2, 236, 17, 237],\n",
       " [1, 20, 9, 38, 69],\n",
       " [2, 11, 5, 238],\n",
       " [1, 7, 239],\n",
       " [2, 240],\n",
       " [98],\n",
       " [2, 241, 17, 242, 22],\n",
       " [1, 71, 8, 243],\n",
       " [14, 25, 17, 99, 8, 244],\n",
       " [45, 245, 246],\n",
       " [95, 2, 47, 4, 78],\n",
       " [1, 247, 248],\n",
       " [1, 52, 53],\n",
       " [249, 3, 34],\n",
       " [4, 49, 100, 250],\n",
       " [4, 251, 252, 253, 23, 4, 35],\n",
       " [98, 65, 19, 254],\n",
       " [4, 255, 3, 97, 96],\n",
       " [54],\n",
       " [1, 23, 256, 92, 8, 257],\n",
       " [1, 20, 9, 94],\n",
       " [4, 258, 11, 43, 259],\n",
       " [2, 25, 17, 29, 19, 260],\n",
       " [4, 101, 3, 261],\n",
       " [84],\n",
       " [1, 262, 2],\n",
       " [1, 7, 263, 13, 5, 264],\n",
       " [73, 3, 4, 27],\n",
       " [2, 11, 265],\n",
       " [266, 267, 13, 44],\n",
       " [14, 3, 93],\n",
       " [1, 7, 268, 62],\n",
       " [10, 3, 6, 40],\n",
       " [2, 23, 5, 56, 269],\n",
       " [1, 20, 9, 21, 270, 13, 44],\n",
       " [14, 271, 5, 61],\n",
       " [4, 272, 273, 274, 51],\n",
       " [1, 23, 275],\n",
       " [276, 11, 36],\n",
       " [1, 277, 63],\n",
       " [1, 7, 278, 9, 4, 279],\n",
       " [1, 7, 280, 281],\n",
       " [1, 7, 83, 48, 2, 86],\n",
       " [10, 90, 3, 67, 46, 16],\n",
       " [282, 65, 4, 283, 39],\n",
       " [284, 19, 285],\n",
       " [38, 286],\n",
       " [1, 287, 288, 8, 289],\n",
       " [290, 291, 21, 5, 101],\n",
       " [1, 7, 292],\n",
       " [14, 3, 8, 293, 18],\n",
       " [14, 3, 6, 64],\n",
       " [1, 18, 88],\n",
       " [1, 25, 17, 21, 294],\n",
       " [8, 295, 100, 57, 5, 296, 297],\n",
       " [1, 24, 2, 5, 61],\n",
       " [15, 57, 9, 298, 5, 299, 300],\n",
       " [1, 7, 47, 4, 26, 49],\n",
       " [11, 2, 301, 12, 12],\n",
       " [1, 24, 9, 302],\n",
       " [31, 303, 10, 30, 12, 12, 12],\n",
       " [2, 85, 11, 64],\n",
       " [10, 304, 87, 3, 17, 62],\n",
       " [37, 2, 25, 28, 79],\n",
       " [8, 34, 3, 6, 305],\n",
       " [15, 25, 17, 99],\n",
       " [66, 70],\n",
       " [2, 306, 8, 42],\n",
       " [1, 32, 38, 102],\n",
       " [66, 307, 308, 42],\n",
       " [102, 46, 16],\n",
       " [14, 3, 5, 309],\n",
       " [14, 310, 26],\n",
       " [1, 24, 22, 311, 312, 60]]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert all sentences in to list of tokens\n",
    "xtokens=tokenizer.texts_to_sequences(x)\n",
    "xtokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "122fbb82-cfe6-47cd-8fc2-e69300b632d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f3e2706d-fb26-4ab5-a002-956508f1781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "def get_maxlen(data):\n",
    "    maxlen=0\n",
    "    for sent in data:\n",
    "        maxlen=max(maxlen,len(sent))\n",
    "    return maxlen\n",
    "maxlen=get_maxlen(xtokens)\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2627c3dc-443c-431c-a900-f8bac84cb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4f435e80-8c3b-4986-8afe-984ec68040c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103, 104,   3, ...,   0,   0,   0],\n",
       "       [106,   3, 107, ...,   0,   0,   0],\n",
       "       [  1,   7, 108, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 14,   3,   5, ...,   0,   0,   0],\n",
       "       [ 14, 310,  26, ...,   0,   0,   0],\n",
       "       [  1,  24,  22, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain=pad_sequences(xtokens,maxlen=maxlen,padding='post')\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fd60fcfb-dbef-4234-896f-addf33c63e70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '0v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[228], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# to_categorical all input needs to be integer\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mint\u001b[39m(label) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[0;32m      5\u001b[0m ytrain\u001b[38;5;241m=\u001b[39mto_categorical(y)\n\u001b[0;32m      6\u001b[0m ytrain\n",
      "Cell \u001b[1;32mIn[228], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# to_categorical all input needs to be integer\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mint\u001b[39m(label) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[0;32m      5\u001b[0m ytrain\u001b[38;5;241m=\u001b[39mto_categorical(y)\n\u001b[0;32m      6\u001b[0m ytrain\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '0v2'"
     ]
    }
   ],
   "source": [
    "# to Hot_Encode Y\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# to_categorical all input needs to be integer\n",
    "y=[int(label) for label in y]\n",
    "ytrain=to_categorical(y)\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9c56da9e-2550-4b86-97a5-aa5e74dae596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4' '3' '3 ' '1 ' '2' '1' '4' '3' '4' '1' '3' '3 ' '2' '2' '4' '3' '2'\n",
      " '3 ' '3 ' '1' '3 ' '2' '2' '2' '0' '1' '0' '4 ' '2' '0v2' '2' '0' '0'\n",
      " '3 ' '4' '0' '2' '1' '3' '1' '0' '4' '0 ' '3' '0 ' '4' '2' '3 ' '4' '2 '\n",
      " '2' '3' '0' '2' '2' '3 ' '2' '3' '2' '2' '3 ' '3' '0 ' '2' '3' '0' '2'\n",
      " '0' '0 ' '2' '3' '2' '4' '1' '3' '3' '0' '0' '3' '2' '0' '3' '0' '2' '2'\n",
      " '4' '2' '2' '0' '0' '2' '3' '0' '4' '2' '1' '2' '3' '3' '2' '3' '0' '3'\n",
      " '0' '2' '0' '2' '3' '4' '3' '1' '3' '4' '3' '2' '3' '3' '3' '1' '4' '4'\n",
      " '2' '2' '1' '1' '2' '3' '2' '3' '4' '2' '3' '0' '2' '0' '0' '4' '3' '4'\n",
      " '2' '3' '2' '3' '4' '2' '1' '2' '4' '3' '1' '3' '2' '3' '2' '2' '3' '3'\n",
      " '2' '4' '0' '0' '0' '3' '0' '0' '1' '1' '2' '2' '2' '0' '3' '2' '3' '3'\n",
      " '1' '2' '2' '4' '2' '3' '1' '2']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "97e03bd8-3386-432a-94dc-add600adcb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid value in `y`: invalid literal for int() with base 10: '0v2'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: Convert y to integers, ignoring invalid entries\n",
    "try:\n",
    "    y = [int(label) for label in y]  # Convert all elements to integers\n",
    "except ValueError as e:\n",
    "    print(f\"Invalid value in `y`: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "25df0eb1-7ad0-44a1-a8fb-9486b452f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned labels: [4, 3, 3, 1, 2, 1, 4, 3, 4, 1, 3, 3, 2, 2, 4, 3, 2, 3, 3, 1, 3, 2, 2, 2, 0, 1, 0, 4, 2, 0, 2, 0, 0, 3, 4, 0, 2, 1, 3, 1, 0, 4, 0, 3, 0, 4, 2, 3, 4, 2, 2, 3, 0, 2, 2, 3, 2, 3, 2, 2, 3, 3, 0, 2, 3, 0, 2, 0, 0, 2, 3, 2, 4, 1, 3, 3, 0, 0, 3, 2, 0, 3, 0, 2, 2, 4, 2, 2, 0, 0, 2, 3, 0, 4, 2, 1, 2, 3, 3, 2, 3, 0, 3, 0, 2, 0, 2, 3, 4, 3, 1, 3, 4, 3, 2, 3, 3, 3, 1, 4, 4, 2, 2, 1, 1, 2, 3, 2, 3, 4, 2, 3, 0, 2, 0, 0, 4, 3, 4, 2, 3, 2, 3, 4, 2, 1, 2, 4, 3, 1, 3, 2, 3, 2, 2, 3, 3, 2, 4, 0, 0, 0, 3, 0, 0, 1, 1, 2, 2, 2, 0, 3, 2, 3, 3, 1, 2, 2, 4, 2, 3, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Replace invalid entries with 0\n",
    "y_cleaned = []\n",
    "for label in y:\n",
    "    try:\n",
    "        y_cleaned.append(int(label))\n",
    "    except ValueError:\n",
    "        y_cleaned.append(0)  # Replace with default value\n",
    "\n",
    "print(\"Cleaned labels:\", y_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "84b059a2-9dde-4bc2-8ca8-e27cb961e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "ytrain = to_categorical(y_cleaned)\n",
    "print(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3d3b4-df08-4138-901f-1e423c82a452",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "253579f0-c178-4038-a48e-05238926f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###   in embedding matrix the size of row=== vocabulary size\n",
    "###    and column==size of word embedding vector\n",
    "embed_size = 100## embed_vector\n",
    "embedding_matrix = np.zeros((len(word2index)+1, embed_size))## row,column\n",
    "# len(word2index)+1=== vocabulary size \n",
    "\n",
    "for word, i in word2index.items(): ## key,value\n",
    "    embed_vector = embedding[word]\n",
    "    embedding_matrix[i] = embed_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d0322841-f506-4a30-a628-195c59517476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [-0.046539,  0.61966 ,  0.56647 , ..., -0.37616 , -0.032502,\n",
       "         0.8062  ],\n",
       "       [-0.49886 ,  0.76602 ,  0.89751 , ..., -0.41179 ,  0.40539 ,\n",
       "         0.78504 ],\n",
       "       ...,\n",
       "       [-0.46263 ,  0.069864,  0.69095 , ..., -0.29174 ,  0.32041 ,\n",
       "         0.21202 ],\n",
       "       [ 0.073242,  0.11134 ,  0.62281 , ...,  0.53417 , -0.1646  ,\n",
       "        -0.27516 ],\n",
       "       [ 0.29019 ,  0.80497 ,  0.31187 , ..., -0.33603 ,  0.45998 ,\n",
       "        -0.11278 ]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0da6551b-bc98-437c-af47-0dcdd18a166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim = len(word2index) + 1,\n",
    "              output_dim = embed_size,\n",
    "              input_length = maxlen,\n",
    "              weights = [embedding_matrix],\n",
    "              trainable = False\n",
    "             ),\n",
    "    \n",
    "    LSTM(units = 16, return_sequences = True), ### LSTM er jaigai (SimpleRNN) o hbe\n",
    "    LSTM(units = 4),\n",
    "    Dense(5, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a4848917-88c2-4c3f-95ae-01aa4a4c4d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.2149 - loss: 1.6049\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2509 - loss: 1.5861 \n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3302 - loss: 1.5719 \n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3973 - loss: 1.5603 \n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3715 - loss: 1.5470 \n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4493 - loss: 1.5299 \n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3866 - loss: 1.5236 \n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3810 - loss: 1.5149 \n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4270 - loss: 1.5090 \n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4591 - loss: 1.4839 \n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5475 - loss: 1.4438 \n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5063 - loss: 1.4277 \n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5267 - loss: 1.3918 \n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5740 - loss: 1.3574 \n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6241 - loss: 1.3006 \n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6347 - loss: 1.2742 \n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5871 - loss: 1.2644 \n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6499 - loss: 1.2287 \n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6473 - loss: 1.1753 \n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7213 - loss: 1.0910 \n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6995 - loss: 1.0715 \n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6789 - loss: 1.0605 \n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7941 - loss: 0.9643 \n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7920 - loss: 0.9384 \n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7972 - loss: 0.9069 \n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7989 - loss: 0.8893 \n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8121 - loss: 0.8384 \n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8047 - loss: 0.8298 \n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8180 - loss: 0.7717 \n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8136 - loss: 0.7780 \n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7961 - loss: 0.7547 \n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7939 - loss: 0.7666 \n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8618 - loss: 0.6767 \n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8143 - loss: 0.7144 \n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8152 - loss: 0.7253 \n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8924 - loss: 0.5895 \n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8484 - loss: 0.6372 \n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8494 - loss: 0.6129 \n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8761 - loss: 0.5815 \n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8494 - loss: 0.6095 \n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8255 - loss: 0.6336 \n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8486 - loss: 0.5932 \n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8483 - loss: 0.5839 \n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8537 - loss: 0.5646 \n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8818 - loss: 0.5181 \n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8790 - loss: 0.5158 \n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8736 - loss: 0.5123 \n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8481 - loss: 0.5521 \n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8426 - loss: 0.5457 \n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8539 - loss: 0.5184 \n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8683 - loss: 0.4993 \n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8603 - loss: 0.4961 \n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8349 - loss: 0.5213 \n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8860 - loss: 0.4499 \n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8386 - loss: 0.5011 \n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8676 - loss: 0.4640 \n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8359 - loss: 0.4981 \n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8285 - loss: 0.5097  \n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8590 - loss: 0.4587 \n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8646 - loss: 0.4379 \n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8526 - loss: 0.4582 \n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8841 - loss: 0.4034 \n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8520 - loss: 0.4375 \n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.4372 \n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8552 - loss: 0.4235 \n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8703 - loss: 0.4192 \n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.3970 \n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8834 - loss: 0.3729 \n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8603 - loss: 0.4066 \n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8749 - loss: 0.3841 \n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8880 - loss: 0.3665 \n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8818 - loss: 0.3676 \n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8680 - loss: 0.3806 \n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8572 - loss: 0.3812\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8616 - loss: 0.3974 \n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8617 - loss: 0.3819 \n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8636 - loss: 0.3982 \n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8535 - loss: 0.3801 \n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8749 - loss: 0.3810 \n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8809 - loss: 0.3660 \n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8915 - loss: 0.3590 \n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9011 - loss: 0.3582 \n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8704 - loss: 0.3711 \n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9200 - loss: 0.3390 \n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9307 - loss: 0.2930 \n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9208 - loss: 0.3333\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9129 - loss: 0.3162 \n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9477 - loss: 0.2966 \n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9337 - loss: 0.3099 \n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9643 - loss: 0.2836 \n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9643 - loss: 0.2884 \n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9553 - loss: 0.2791 \n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9196 - loss: 0.3208 \n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8927 - loss: 0.4269 \n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9290 - loss: 0.3123 \n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8718 - loss: 0.3567 \n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8908 - loss: 0.3377 \n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9627 - loss: 0.2823\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.2729 \n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9767 - loss: 0.2720 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ad2b667290>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(xtrain, ytrain, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "41f8c467-2b5b-4e89-a8e6-7a5a18d89715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5199346 , 0.05684804, 0.14112005, 0.11209705, 0.17000026],\n",
       "       [0.02390837, 0.0065205 , 0.06908417, 0.8877499 , 0.01273703],\n",
       "       [0.17768537, 0.28140557, 0.15929025, 0.03936006, 0.34225878]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predictionn\n",
    "test = [\"I feel good\", \"I feel very bad\", \"lets eat dinner\"]\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "Xtest = pad_sequences(test_seq, maxlen = maxlen, padding = 'post', truncating = 'post')\n",
    "\n",
    "y_pred = model.predict(Xtest)\n",
    "y_pred\n",
    "###     in y_pred we need to get theindex where the max value  is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a4bf659a-addd-424d-956d-e0d0a1271408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"I feel good\", \"I feel very bad\", \"lets eat dinner\"]\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "Xtest = pad_sequences(test_seq, maxlen = maxlen, padding = 'post', truncating = 'post')\n",
    "\n",
    "y_pred = model.predict(Xtest)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "07352981-5408-4c2c-82a4-577dfe6d0f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "I feel good ❤️\n",
      "I feel very bad 😞\n",
      "lets eat dinner 🍽️\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = [\"I feel good\", \"I feel very bad\", \"lets eat dinner\"]\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "Xtest = pad_sequences(test_seq, maxlen = maxlen, padding = 'post', truncating = 'post')\n",
    "\n",
    "y_pred = model.predict(Xtest)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "for i in range(len(test)):\n",
    "    print(test[i], label_to_emoji(y_pred[i])) #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd161f8-b086-4f44-895a-218a275c9cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000deb95-b0b2-4021-b5a2-8f25732ee548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
